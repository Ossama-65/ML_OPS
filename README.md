# Documentation ComplÃ¨te et Approfondie du Projet MLOps

## Introduction ğŸŒŸ

Bienvenue dans la documentation complÃ¨te du projet MLOps. Ce projet vise Ã  dÃ©montrer l'application pratique et systÃ©matique des meilleures pratiques en Machine Learning Operations (MLOps). En combinant des outils modernes comme Terraform, Ansible, Docker, et GitHub Actions, nous avons conÃ§u une solution robuste pour la gestion, le dÃ©ploiement et la surveillance des pipelines ML. ğŸŒŸ Notre objectif principal est de garantir la reproductibilitÃ©, la transparence et l'automatisation complÃ¨te des processus, tout en rÃ©pondant aux dÃ©fis courants rencontrÃ©s dans les environnements ML industriels.

---

## Objectifs du Projet ğŸ¯

1. **Infrastructure Cloud**  
   - Provisionnement et gestion des ressources AWS via Terraform.  
   - Configuration automatisÃ©e des serveurs avec Ansible.  

2. **Application ML**  
   - DÃ©veloppement d'un pipeline complet intÃ©grant la transformation des donnÃ©es, l'entraÃ®nement et la prÃ©diction.  
   - Suivi et gestion des modÃ¨les ML avec MLflow pour le versioning et la traÃ§abilitÃ©.  

3. **Pipeline CI/CD**  
   - DÃ©ploiement et intÃ©gration continus grÃ¢ce Ã  GitHub Actions.  

4. **Monitoring et Visualisation**  
   - Collecte de mÃ©triques et surveillance en temps rÃ©el via Prometheus et Grafana.  

5. **Documentation et Collaboration**  
   - Documentation dÃ©taillÃ©e couvrant chaque composant et Ã©tape du projet.  
   - Explications des choix techniques et adoption des meilleures pratiques.  

---

## Contexte du Projet ğŸŒ

Avec la montÃ©e en puissance du Machine Learning dans divers secteurs, les dÃ©fis liÃ©s Ã  la mise Ã  l'Ã©chelle, Ã  la maintenabilitÃ© et au dÃ©ploiement continu des modÃ¨les ML sont devenus critiques. Ce projet vise Ã  rÃ©pondre Ã  ces dÃ©fis en :

- **Standardisant** le dÃ©veloppement des pipelines ML.  
- **Facilitant** la collaboration entre Ã©quipes interfonctionnelles.  
- **RÃ©duisant** les erreurs humaines grÃ¢ce Ã  l'automatisation des processus critiques.

Les entreprises adoptant des approches MLOps comme celle-ci bÃ©nÃ©ficient d'une augmentation de leur efficacitÃ© et d'une meilleure reproductibilitÃ© des rÃ©sultats ML. ğŸŒ

---

## Architecture Globale du Projet ğŸ—ï¸

### SchÃ©ma d'Architecture

```
+-------------------+
| Utilisateur       |
+--------+----------+
         |
         v
+--------+----------+
| API Flask         |
+--------+----------+
         |
         v
+-------------------+
| ModÃ¨les ML        |
+-------------------+
         |
         v
+-------------------+
| Infrastructure    |
+-------------------+
```

### Composants ClÃ©s

1. **API Flask** : Une interface utilisateur pour interagir avec les modÃ¨les et effectuer des prÃ©dictions. ğŸŒ
2. **ModÃ¨les ML** : EnregistrÃ©s, versionnÃ©s et gÃ©rÃ©s avec MLflow.  
3. **Infrastructure** : DÃ©ployÃ©e sur AWS via Terraform et configurÃ©e avec Ansible.  
4. **Monitoring** : Surveillance et alertes configurÃ©es grÃ¢ce Ã  Prometheus et Grafana.  

---

## Ã‰tapes de DÃ©ploiement ğŸ› ï¸

### 1. Cloner le DÃ©pÃ´t
```bash
git clone https://github.com/Ossama-65/ML_OPS.git
cd ML_OPS
```

### 2. Provisionner l'Infrastructure
```bash
cd terraform
terraform init
terraform apply
```

### 3. Configurer les Serveurs
```bash
cd ansible
ansible-playbook -i inventory playbook.yml
```

### 4. DÃ©ployer le Monitoring
```bash
cd monitoring
sudo docker-compose up -d
```

Ces Ã©tapes garantissent que l'infrastructure, les configurations, et les outils de surveillance sont opÃ©rationnels avant de passer au dÃ©veloppement et Ã  l'utilisation des modÃ¨les ML. ğŸ›¡ï¸

---

## Description des Modules ğŸ“‚

### 1. **Dossier `src`**  
Ce dossier regroupe tout le code source relatif aux Ã©tapes du pipeline ML :

- `data/make_data.py` : GÃ©nÃ©ration de donnÃ©es factices pour les tests.  
- `features/build_features.py` : PrÃ©traitement et gÃ©nÃ©ration des caractÃ©ristiques.  
- `models/train_model.py` : EntraÃ®nement des modÃ¨les ML.  
- `models/predict.py` : Utilisation des modÃ¨les pour des prÃ©dictions.  
- `lib/utils.py` : Fonctions utilitaires partagÃ©es entre les scripts.

### 2. **Dossier `monitoring`**  
Inclut les configurations nÃ©cessaires pour la surveillance en temps rÃ©el :

- **Prometheus** : Fichier `prometheus.yml` pour la collecte des mÃ©triques.  
- **Grafana** : Dashboards dÃ©finis dans `mlops_dashboard.json` et `infra_dashboard.json`.  

### 3. **Dossier `terraform`**  
Automatise le provisionnement des ressources cloud AWS :

- **S3** : Stockage des donnÃ©es et des modÃ¨les.  
- **EC2** : ExÃ©cution des scripts et des API.  
- **VPC** : Isolation sÃ©curisÃ©e de l'environnement.

### 4. **Fichier `requirements.txt`**  
SpÃ©cifie les bibliothÃ¨ques Python nÃ©cessaires au projet, garantissant la compatibilitÃ© et la portabilitÃ©. ğŸ“‹

---

## API Documentation ğŸŒ

### Endpoint `/predict`

- **MÃ©thode** : `POST`  
- **Description** : Permet de soumettre des caractÃ©ristiques et de recevoir des prÃ©dictions.  
- **Exemple** :

#### RequÃªte
```json
{
  "feature1": [1, 2, 3],
  "feature2": [10, 20, 30]
}
```

#### RÃ©ponse
```json
{
  "predictions": [0, 1, 0]
}
```

L'API est conÃ§ue pour une interopÃ©rabilitÃ© maximale et une expÃ©rience utilisateur fluide. ğŸš€

---

## CI/CD avec GitHub Actions ğŸ¤–

Chaque commit dÃ©clenche automatiquement :

1. **Tests AutomatisÃ©s** : Analyse de la qualitÃ© du code et exÃ©cution des tests unitaires.  
2. **Build Docker** : Construction et validation des images Docker.  
3. **DÃ©ploiement** : Mise Ã  jour automatique des modÃ¨les et de l'API en production.

L'intÃ©gration continue garantit que chaque modification respecte les normes de qualitÃ© dÃ©finies pour le projet. ğŸ”§

---

## Monitoring ğŸ”

### Prometheus

- Collecte les mÃ©triques des composants de l'infrastructure et des applications.  
- GÃ©nÃ¨re des alertes configurÃ©es dans `alerts.rules.yml` en cas de dÃ©faillances ou de seuils critiques dÃ©passÃ©s.

### Grafana

- Fournit des dashboards interactifs pour visualiser les donnÃ©es collectÃ©es :
  - **mlops_dashboard.json** : Suivi des indicateurs clÃ©s liÃ©s aux modÃ¨les ML.  
  - **infra_dashboard.json** : Ã‰tat de l'infrastructure cloud.  

Ces outils permettent de dÃ©tecter rapidement les anomalies et d'assurer une disponibilitÃ© continue du systÃ¨me. ğŸ“Š

---

## RÃ©solution des ProblÃ¨mes ğŸ”§

1. **Erreur AWS CLI** : Assurez-vous que vos identifiants AWS sont correctement configurÃ©s dans `~/.aws/credentials`.  
2. **Ã‰chec du Terraform Apply** : VÃ©rifiez les permissions associÃ©es Ã  votre compte AWS.  
3. **Docker ne dÃ©marre pas** : RedÃ©marrez le service Docker avec la commande `sudo systemctl restart docker`.  

Ces solutions couvrent les problÃ¨mes les plus courants rencontrÃ©s lors de la mise en Å“uvre de l'infrastructure et des outils.

---

## Auteurs ğŸ§‘â€ğŸ“ğŸ§‘â€ğŸ“âœï¸

- Manel Zerguit : Responsable de l'intÃ©gration CI/CD.
- Ossama Louridi : SpÃ©cialiste en monitoring et infrastructure cloud.
- Aziz BenAyed : DÃ©veloppement des pipelines ML et API. 


Ce document a Ã©tÃ© conÃ§u pour offrir une vue dÃ©taillÃ©e et pratique du projet MLOps. Il s'adresse Ã  la fois aux dÃ©butants et aux experts souhaitant implÃ©menter une solution ML complÃ¨te et fiable.

