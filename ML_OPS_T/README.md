# Documentation avancÃ©e du Projet MLOps

## Introduction ğŸ“ŠğŸŒğŸš€
Ce projet explore le dÃ©veloppement d'une chaÃ®ne complÃ¨te MLOps qui fusionne les meilleures pratiques DevOps avec des outils spÃ©cialisÃ©s en Machine Learning. L'objectif est d'automatiser et d'optimiser le cycle de vie du Machine Learning en adoptant une mÃ©thodologie systÃ©matique fondÃ©e sur l'Infrastructure as Code (IaC) et des pipelines CI/CD robustes. L'intÃ©gration couvre l'infrastructure cloud, le versioning des modÃ¨les, le monitoring des performances et une documentation exhaustive pour garantir la reproductibilitÃ© et la transparence.

Ce projet met en avant des solutions adaptÃ©es aux dÃ©fis courants du Machine Learning, notamment la gestion des versions des donnÃ©es et des modÃ¨les, le dÃ©ploiement d'API fiables et le suivi en temps rÃ©el des mÃ©triques opÃ©rationnelles via des outils de monitoring avancÃ©s.

## Structure du Projet ğŸ“ğŸ”„ğŸ 

La structure de ce projet suit une architecture modulaire bien dÃ©finie :

```
MLOps-END-TO-END/
â”œâ”€â”€ .github/workflows
â”‚   â”œâ”€â”€ ci-cd.yml
â”œâ”€â”€ ansible/
â”‚   â”œâ”€â”€ playbook.yml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed_data.csv
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”‚   â”œâ”€â”€ alerts.rules.yml
â”‚   â”œâ”€â”€ grafana/
â”‚       â”œâ”€â”€ datasources/datasource.yml
â”‚       â”œâ”€â”€ dashboards/mlops_dashboard.json
â”‚       â”œâ”€â”€ dashboards/infra_dashboard.json
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analyses.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/make_data.py
â”‚   â”œâ”€â”€ features/build_features.py
â”‚   â”œâ”€â”€ models/train_model.py
â”‚   â”œâ”€â”€ models/predict.py
â”‚   â”œâ”€â”€ lib/utils.py
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_app.py
```

Cette architecture est conÃ§ue pour faciliter le dÃ©veloppement collaboratif et le dÃ©ploiement Ã  grande Ã©chelle.

## Installation et Configuration ğŸš€ğŸŒâš™ï¸

### PrÃ©requis ğŸ”§ğŸ’¡
Pour configurer et exÃ©cuter ce projet, assurez-vous d'avoir les Ã©lÃ©ments suivants :
- **Docker** : Pour conteneuriser les applications.
- **Terraform** : Pour provisionner l'infrastructure cloud.
- **Ansible** : Pour automatiser la configuration des serveurs.
- **AWS CLI** : Pour interagir avec les services AWS tels que S3.
- **Python 3.8+** : Avec `pip` pour la gestion des dÃ©pendances.

### Ã‰tapes d'installation ğŸ› ï¸ğŸŒ

1. **Cloner le Repository** :
   ```bash
   git clone https://github.com/ton-repo/mlops-end-to-end.git
   cd mlops-end-to-end
   ```

2. **Configurer les Variables Terraform** :
   Modifiez `terraform/variables.tf` pour renseigner vos identifiants AWS et la rÃ©gion souhaitÃ©e.

3. **Provisionner l'Infrastructure** :
   ```bash
   cd terraform
   terraform init
   terraform apply
   ```

4. **Configurer les Serveurs avec Ansible** :
   ```bash
   cd ansible
   ansible-playbook -i inventory playbook.yml
   ```

5. **DÃ©ployer le Monitoring** :
   ```bash
   cd monitoring
   docker-compose up -d
   ```

6. **Installer les DÃ©pendances Python** :
   ```bash
   pip install -r requirements.txt
   ```

7. **Lancer l'API Flask** :
   ```bash
   python3 src/app.py
   ```

## Utilisation ğŸ”„ğŸ“ŠğŸŒ

### Pipeline ML

1. **GÃ©nÃ©ration des DonnÃ©es** :
   ```bash
   python3 src/data/make_data.py
   ```

2. **Transformation des DonnÃ©es** :
   ```bash
   python3 src/features/build_features.py --environment prod
   ```

3. **EntraÃ®nement du ModÃ¨le** :
   ```bash
   python3 src/models/train_model.py --name my_model --environment prod
   ```

4. **PrÃ©diction avec le ModÃ¨le** :
   ```bash
   python3 src/models/predict.py --name my_model --model latest --environment prod
   ```

### Monitoring ğŸ–…âš™ï¸âš¡ï¸

- AccÃ©der Ã  Grafana : `http://<IP_SERVEUR>:3000`
- AccÃ©der Ã  Prometheus : `http://<IP_SERVEUR>:9090`

### CI/CD avec GitHub Actions âš“ï¸âŒ›âš–ï¸

Chaque push dÃ©clenche automatiquement les pipelines CI/CD dÃ©finis dans `.github/workflows/ci-cd.yml`. Les Ã©tapes incluent :
- Tests automatisÃ©s.
- Construction des images Docker.
- DÃ©ploiement dans l'environnement de production.

## Documentation des APIs ğŸ”ğŸ“Šâš™ï¸

### Endpoint : `/predict`
- **MÃ©thode** : `POST`
- **Payload** :
  ```json
  {
    "feature1": [1, 2, 3],
    "feature2": [10, 20, 30]
  }
  ```
- **RÃ©ponse** :
  ```json
  {
    "predictions": [0, 1, 0]
  }
  ```

## Monitoring et Troubleshooting ğŸ”§ğŸ› ï¸ğŸ’¡

### Visualisation des Metrics
Grafana et Prometheus permettent un suivi dÃ©taillÃ© des performances de l'infrastructure et des modÃ¨les. Les dashboards sont configurÃ©s pour afficher les mÃ©triques essentielles :
- Temps de rÃ©ponse des API.
- DisponibilitÃ© des services.
- Performances des modÃ¨les (ex. : prÃ©cision, F1-score).

### RÃ©solution des ProblÃ¨mes Courants

1. **Erreur de connexion S3** :
   - VÃ©rifiez que vos identifiants AWS sont correctement configurÃ©s dans `~/.aws/credentials`.
   - Assurez-vous que le bucket spÃ©cifiÃ© existe.

2. **ProblÃ¨me avec Docker** :
   - RedÃ©marrez le service Docker :
     ```bash
     sudo systemctl restart docker
     ```

3. **Erreur Terraform** :
   - VÃ©rifiez vos permissions AWS.
   - Supprimez les ressources conflictuelles avant de relancer `terraform apply`.

## Auteurs ğŸ§‘â€ğŸ“ğŸ§‘â€ğŸ“âœï¸

- Manel Zerguit : Responsable de l'intÃ©gration CI/CD.
- Ossama Louridi : SpÃ©cialiste en monitoring et infrastructure cloud.
- Aziz BenAyed : DÃ©veloppement des pipelines ML et API.


